@ARTICLE{tpami2017Zeki, 
author={I. Z. Yalniz and R. Manmatha}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Dependence models for searching text in document images}, 
year={2017}, 
volume={PP}, 
number={99}, 
pages={1-1}, 
abstract={The main goal of existing word spotting approaches for searching document images has been the identification of visually similar word images in the absence of high quality text recognition output. Searching for a piece of arbitrary text is not possible unless the user identifies a sample word image from the document collection or generates the query word image synthetically. To address this problem, a Markov Random Field (MRF) framework is proposed for searching document images and shown to be effective for searching arbitrary text in real time for books printed in English (Latin script), Telugu and Ottoman scripts. The English experiments demonstrate that the dependencies between the visual terms and letter bigrams can be automatically learned using noisy OCR output. It is also shown that OCR text search accuracy can be significantly improved if it is combined with the proposed approach. No commercial OCR engine is available for Telugu or Ottoman script. In these cases the dependencies are trained using manually annotated document images. It is demonstrated that the trained model can be directly used to resolve arbitrary text queries across books despite font type and size differences. The proposed approach outperforms a state-of-the-art BLSTM baseline in these contexts.}, 
keywords={Engines;Feature extraction;Image resolution;Noise measurement;Optical character recognition software;Text recognition;Visualization;Markov Random Fields;document image search;image retrieval;word spotting}, 
doi={10.1109/TPAMI.2017.2780108}, 
ISSN={0162-8828}, 
month={},
}


@ARTICLE{tpami2017WZhou, 
author={W. Zhou and H. Li and J. Sun and Q. Tian}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Collaborative Index Embedding for Image Retrieval}, 
year={2017}, 
volume={PP}, 
number={99}, 
pages={1-1}, 
abstract={In content-based image retrieval, SIFT feature and the feature from deep convolutional neural network (CNN) have demonstrated promising performance. To fully explore both visual features in a unified framework for effective and efficient retrieval, we propose a collaborative index embedding method to implicitly integrate the index matrices of them. We formulate the index embedding as an optimization problem from the perspective of neighborhood sharing and solve it with an alternating index update scheme. After the iterative embedding, only the embedded CNN index is kept for on-line query, which demonstrates significant gain in retrieval accuracy, with very economical memory cost. Extensive experiments have been conducted on the public datasets with million-scale distractor images. The experimental results reveal that, compared with the recent state-of-the-art retrieval algorithms, our approach achieves competitive accuracy performance with less memory overhead and efficient query computation.}, 
keywords={Feature extraction;Image retrieval;Indexing;Neural networks;Visualization;CNN feature;Image retrieval;SIFT;index embedding;inverted index}, 
doi={10.1109/TPAMI.2017.2676779}, 
ISSN={0162-8828}, 
month={},}

@ARTICLE{tpami2017Ren, 
author={Y. Ren and Y. Wang and J. Zhu}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Spectral Learning for Supervised Topic Models}, 
year={2017}, 
volume={PP}, 
number={99}, 
pages={1-1}, 
abstract={Supervised topic models simultaneously model the latent topic structure of large collections of documents and a response variable associated with each document. Existing inference methods are based on variational approximation or Monte Carlo sampling, which often suffers from the local minimum defect. Spectral methods have been applied to learn unsupervised topic models, such as latent Dirichlet allocation (LDA), with provable guarantees. This paper investigates the possibility of applying spectral methods to recover the parameters of supervised LDA (sLDA). We first present a two-stage spectral method, which recovers the parameters of LDA followed by a power update method to recover the regression model parameters. Then, we further present a single-phase spectral algorithm to jointly recover the topic distribution matrix as well as the regression weights. Our spectral algorithms are provably correct and computationally efficient. We prove a sample complexity bound for each algorithm and subsequently derive a sufficient condition for the identifiability of sLDA. Thorough experiments on synthetic and real-world datasets verify the theory and demonstrate the practical effectiveness of the spectral algorithms. In fact, our results on a large-scale review rating dataset demonstrate that our single-phase spectral algorithm alone gets comparable or even better performance than state-of-the-art methods, while previous work on spectral methods has rarely reported such promising performance.}, 
keywords={Algorithm design and analysis;Analytical models;Complexity theory;Computational modeling;Maximum likelihood estimation;Robustness;Tensile stress;Spectral methods;methods of moments;supervised topic models}, 
doi={10.1109/TPAMI.2017.2682085}, 
ISSN={0162-8828}, 
month={},}

@inproceedings{sigir2016Kenny,
 author = {Zanibbi, Richard and Davila, Kenny and Kane, Andrew and Tompa, Frank Wm.},
 title = {Multi-Stage Math Formula Search: Using Appearance-Based Similarity Metrics at Scale},
 booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '16},
 year = {2016},
 isbn = {978-1-4503-4069-4},
 location = {Pisa, Italy},
 pages = {145--154},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2911451.2911512},
 doi = {10.1145/2911451.2911512},
 acmid = {2911512},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {inverted index, mathematical information retrieval (MIR), query-by-expression, subtree similarity},
} 

@inproceedings{sigir2016KennyVideos,
 author = {Davila, Kenny},
 title = {Appearance-Based Retrieval of Mathematical Notation in Documents and Lecture Videos},
 booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '16},
 year = {2016},
 isbn = {978-1-4503-4069-4},
 location = {Pisa, Italy},
 pages = {1165--1165},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/2911451.2911477},
 doi = {10.1145/2911451.2911477},
 acmid = {2911477},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {content-based image retrieval, graph-based retrieval, mathematical information retrieval},
} 

@inproceedings{sigir2017Kenny,
 author = {Davila, Kenny and Zanibbi, Richard},
 title = {Layout and Semantics: Combining Representations for Mathematical Formula Search},
 booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 location = {Shinjuku, Tokyo, Japan},
 pages = {1165--1168},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3077136.3080748},
 doi = {10.1145/3077136.3080748},
 acmid = {3080748},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {formula retrieval, operator tree, symbol layout tree},
} 


@ARTICLE{susanDumais90latent,
    author = {Scott Deerwester and Susan T. Dumais and George W. Furnas and Thomas K. Landauer and Richard Harshman},
    title = {Indexing by latent semantic analysis},
    journal = {JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE},
    year = {1990},
    volume = {41},
    number = {6},
    pages = {391--407}
}

@inproceedings{NeuralLanForQueryCompletion,
 author = {Park, Dae Hoon and Chiba, Rikio},
 title = {A Neural Language Model for Query Auto-Completion},
 booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 abstract = {Query auto-completion (QAC) systems suggest queries that complete a user's text as the user types each character. Such queries are typically selected among previously stored queries, based on specific attributes such as popularity. However, queries cannot be suggested if a user's text does not match any queries in the storage. In order to suggest queries for previously unseen text, we propose a neural language model that learns how to generate a query from a starting text, a prefix. Specifically, we employ a recurrent neural network to handle prefixes in variable length. We perform the first neural language model experiments for QAC, and we evaluate the proposed methods with a public data set. Empirical results show that the proposed methods are as effective as traditional methods for previously seen queries and are superior to the state-of-the-art QAC method for previously unseen queries.},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 location = {Shinjuku, Tokyo, Japan},
 pages = {1189--1192},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3077136.3080758},
 doi = {10.1145/3077136.3080758},
 acmid = {3080758},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {neural language model, query auto-completion, recurrent neural network},
}

@inproceedings{mailandlogQueryCompletion,
 author = {Horovitz, Michal and Lewin-Eytan, Liane and Libov, Alex and Maarek, Yoelle and Raviv, Ariel},
 title = {Mailbox-Based vs. Log-Based Query Completion for Mail Search},
 booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 location = {Shinjuku, Tokyo, Japan},
 pages = {937--940},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3077136.3080683},
 doi = {10.1145/3077136.3080683},
 acmid = {3080683},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mail search, query auto completion, query suggestion},
 abstract = {Recent research studies on mail search have shown that the longer the query, the better the quality of results, yet a majority of mail queries remain very short and searchers struggle with formulating queries. A known mechanism to assist users in this task is query auto-completion, which has been highly successful in Web search, where it leverages huge logs of queries issued by hundreds of millions of users. This approach cannot be applied directly to mail search as personal query logs are small, mailboxes are not shared and other users' queries are not necessarily generalizable to all. We therefore propose here to leverage the mailbox content in order to generate suggestions, taking advantage of mail-specific features. We then compare this approach to a recent study that augments an individual user's mail search history with query logs from "similar users'', where the similarity is driven by demographics. Finally we show how combining both types of approaches allows for better suggestions quality but also increases the chance that the desired message be retrieved. We validate our claims via a manual qualitative evaluation and large scale quantitative experiments conducted on the query log of Yahoo Mail.},
} 

@inproceedings{effi-struct-for-n-gram,
 author = {Pibiri, Giulio Ermanno and Venturini, Rossano},
 title = {Efficient Data Structures for Massive N-Gram Datasets},
 booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 abstract = {In this paper we study the problem of reducing the space required by the representation of such datasets, maintaining the capability of looking up for a given N-gram within micro seconds. For this purpose we describe compressed, exact and lossless data structures that achieve, at the same time, high space reductions and no time degradation with respect to state-of-the-art software packages. In particular, we present a trie data structure in which each word following a context of fixed length k, i.e., its preceding k words, is encoded as an integer whose value is proportional to the number of words that follow such context. Since the number of words following a given context is typically very small in natural languages, we are able to lower the space of representation to compression levels that were never achieved before. Despite the significant savings in space, we show that our technique introduces a negligible penalty at query time.},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 location = {Shinjuku, Tokyo, Japan},
 pages = {615--624},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3077136.3080798},
 doi = {10.1145/3077136.3080798},
 acmid = {3080798},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data compression, elias-fano, language models, performance},
} 

@inproceedings{DiSanto-AC-Approaches,
 author = {Di Santo, Giovanni and McCreadie, Richard and Macdonald, Craig and Ounis, Iadh},
 title = {Comparing Approaches for Query Autocompletion},
 booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 abstract = {There are a large number of approaches to automatically rank candidate queries for the purposes of auto-completion. However, no study exists that compares these approaches on a single dataset. Hence, in this paper, we present a comparison study between current approaches to rank candidate query completions for the user query as it is typed. Using a query-log and document corpus from a commercial medical search engine, we study the performance of 11 candidate query ranking approaches from the literature and analyze where they are effective. We show that the most effective approaches to query auto-completion are largely dependent on the number of characters that the user has typed so far, with the most effective approach differing for short and long prefixes. Moreover, we show that if personalized information is available about the searcher, this additional information can be used to more effectively rank query candidate completions, regardless of the prefix length.},
 series = {SIGIR '15},
 year = {2015},
 isbn = {978-1-4503-3621-5},
 location = {Santiago, Chile},
 pages = {775--778},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2766462.2767829},
 doi = {10.1145/2766462.2767829},
 acmid = {2767829},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {information retrieval, query completion},
} 

@inproceedings{query-suggestion-metrics,
 author = {Kharitonov, Eugene and Macdonald, Craig and Serdyukov, Pavel and Ounis, Iadh},
 title = {User Model-based Metrics for Offline Query Suggestion Evaluation},
 booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 abstract = {Inspired by the cascade user models and state-of-the-art evaluation metrics in the web search domain, we address the query suggestion evaluation, by first studying the users behaviour from a search engine's query log and thereby deriving a new family of user models describing the users interaction with a query suggestion mechanism. Next, assuming a query log-based evaluation approach, we propose two new metrics to evaluate query suggestions, pSaved and eSaved. Both metrics are parameterised by a user model.},
 series = {SIGIR '13},
 year = {2013},
 isbn = {978-1-4503-2034-4},
 location = {Dublin, Ireland},
 pages = {633--642},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2484028.2484041},
 doi = {10.1145/2484028.2484041},
 acmid = {2484041},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {evaluation measures, query suggestions, user models},
} 

@inproceedings{session-context,
 author = {Mitra, Bhaskar},
 title = {Exploring Session Context Using Distributed Representations of Queries and Reformulations},
 booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '15},
 abstract = {In this paper, we study the distributed representation of queries learnt by deep neural network models, such as the Convolutional Latent Semantic Model, and show that they can be used to represent query reformulations as vectors. These reformulation vectors exhibit favourable properties such as mapping semantically and syntactically similar query changes closer in the embedding space. Our work is motivated by the success of continuous space language models in capturing relationships between words and their meanings using offset vectors. We demonstrate a way to extend the same intuition to represent query reformulations. Furthermore, we show that the distributed representations of queries and reformulations are both useful for modelling session context for query prediction tasks, such as for query auto-completion (QAC) ranking. Our empirical study demonstrates that short-term (session) history context features based on these two representations improves the mean reciprocal rank (MRR) for the QAC ranking task by more than 10 percent over a supervised ranker baseline. Our results also show that by using features based on both these representations together we achieve a better performance, than either of them individually.},
 year = {2015},
 isbn = {978-1-4503-3621-5},
 location = {Santiago, Chile},
 pages = {3--12},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2766462.2767702},
 doi = {10.1145/2766462.2767702},
 acmid = {2767702},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {contextual search, deep learning, query auto-completion},
} 

@inproceedings{rarePrefixQueryAutoComplete,
 author = {Mitra, Bhaskar and Craswell, Nick},
 title = {Query Auto-Completion for Rare Prefixes},
 booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
 series = {CIKM '15},
 year = {2015},
 isbn = {978-1-4503-3794-6},
 location = {Melbourne, Australia},
 pages = {1755--1758},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2806416.2806599},
 doi = {10.1145/2806416.2806599},
 acmid = {2806599},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {deep learning, query auto-completion},
} 

@inproceedings{context-sensitive-auto-completion,
 author = {Schmidt, Andreas and Hoffart, Johannes and Milchevski, Dragan and Weikum, Gerhard},
 title = {Context-Sensitive Auto-Completion for Searching with Entities and Categories},
 booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '16},
 year = {2016},
 isbn = {978-1-4503-4069-4},
 location = {Pisa, Italy},
 pages = {1097--1100},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2911451.2911461},
 doi = {10.1145/2911451.2911461},
 acmid = {2911461},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {categories, context adaptive, corpus adaptive, entities, semantic-auto-completion},
} 

@book{queryAutoCompleteSurvey2016,
 author = {Cai, Fei and de Rijke, Maarten},
 title = {A Survey of Query Auto Completion in Information Retrieval},
 year = {2016},
 isbn = {168083200X, 9781680832006},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
}
